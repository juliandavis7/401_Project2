{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Soft-SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_comp(X,y,C,w0):\n",
    "    summands_of_X = X[X.dot(w0) * y <= 1]\n",
    "    summands_of_y = y[summands_of_X.index]\n",
    "    Y = []\n",
    "    for i in range(summands_of_X.shape[1]):\n",
    "        Y.append(list(summands_of_y))\n",
    "    summands = -1*np.multiply(pd.DataFrame(Y).values.T,summands_of_X)\n",
    "    gradient = w0 + C*summands.sum()\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_comp(X,y,C,w0,batch):\n",
    "    Xsamp = X.sample(batch)\n",
    "    ysamp = y[Xsamp.index]\n",
    "    summands_of_X = Xsamp[Xsamp.dot(w0) * ysamp <= 1]\n",
    "    summands_of_y = ysamp[summands_of_X.index]\n",
    "    Y = []\n",
    "    for i in range(summands_of_X.shape[1]):\n",
    "        Y.append(list(summands_of_y))\n",
    "    summands = -1*np.multiply(pd.DataFrame(Y).values.T,summands_of_X)\n",
    "    gradient = w0 + C*(1/batch)*summands.sum()\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_SVM_training(X,y,C,w0,eps,lr,n,batch):\n",
    "    # X is training data\n",
    "    # y is labels\n",
    "    # C is penalty of how hard to be\n",
    "    # w is initial weights vector (np.array)\n",
    "    # eps is convergence criterion\n",
    "    # lr is learning rate\n",
    "    \n",
    "    # Computing gradient of L\n",
    "    i = 0\n",
    "    gradw = stochastic_gradient_comp(X,y,C,w0,batch)\n",
    "    w1 = w0 - lr*gradw\n",
    "    while(np.linalg.norm(w0-w1) > eps):\n",
    "        w0 = w1\n",
    "        w1 = w0 - lr*gradient_comp(X,y,C,w0)\n",
    "        i = i + 1\n",
    "        if(i%10==0):\n",
    "            print(i)\n",
    "        if i == n:\n",
    "            break\n",
    "    print(np.linalg.norm(w0-w1))\n",
    "    return w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Testing_soft_SVM(X,y,w):\n",
    "    # X is the X_test set (in the form of the training set). There should\n",
    "    # be a column of ones at the same spot as there is in the training.\n",
    "    # y is the y_test actual values\n",
    "    # w is the out put weights from the soft_SVM_training\n",
    "    vals = X.values.dot(w)\n",
    "    predictions = pd.Series((vals/abs(vals)).astype(int))\n",
    "    TP = sum(y[(predictions[(predictions > 0)].index)] > 0)\n",
    "    TN = sum(y[predictions[(predictions < 0)].index] < 0)\n",
    "    FP = sum(y[predictions[(predictions > 0)].index] < 0)\n",
    "    FN = sum(y[predictions[(predictions < 0)].index] > 0)\n",
    "    print(\"TP\",TP)\n",
    "    print(\"TN\",TN)\n",
    "    print(\"FP\",FP)\n",
    "    print(\"FN\",FN)\n",
    "    accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    f1 = 2*(precision*recall)/(precision+recall)\n",
    "    return {\"accuracy\":accuracy,\"precision\":precision,\"recall\":recall, \"f1\":f1}\n",
    "    #return {\"accuracy\":accuracy,\"recall\":recall}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2893_10.txt</td>\n",
       "      <td>Walt Disney's CINDERELLA takes a story everybo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7944_9.txt</td>\n",
       "      <td>Have you ever, or do you have, a pet who's bee...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11725_10.txt</td>\n",
       "      <td>I suck at gratuitous Boob references, so i'm j...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1587_10.txt</td>\n",
       "      <td>Does anyone know, where I can see or download ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10297_8.txt</td>\n",
       "      <td>Well not actually. This movie is very entertai...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           File                                             Review  Label\n",
       "0   2893_10.txt  Walt Disney's CINDERELLA takes a story everybo...      1\n",
       "1    7944_9.txt  Have you ever, or do you have, a pet who's bee...      1\n",
       "2  11725_10.txt  I suck at gratuitous Boob references, so i'm j...      1\n",
       "3   1587_10.txt  Does anyone know, where I can see or download ...      1\n",
       "4   10297_8.txt  Well not actually. This movie is very entertai...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df = pd.read_csv(\"Training_data.csv\").drop(\"Unnamed: 0\",axis=1)\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2893_10.txt</td>\n",
       "      <td>\"Rush in Rio\" is, no doubt, one of the most ex...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8705_10.txt</td>\n",
       "      <td>I have seen a number of horror movies to know ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11725_10.txt</td>\n",
       "      <td>I'm a fan of B grade 80s films in which the he...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9859_8.txt</td>\n",
       "      <td>I think that Pierre Léaud, or his character, t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12409_10.txt</td>\n",
       "      <td>This picture doesn't have any big explosions o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           File                                             Review  Label\n",
       "0   2893_10.txt  \"Rush in Rio\" is, no doubt, one of the most ex...      1\n",
       "1   8705_10.txt  I have seen a number of horror movies to know ...      1\n",
       "2  11725_10.txt  I'm a fan of B grade 80s films in which the he...      1\n",
       "3    9859_8.txt  I think that Pierre Léaud, or his character, t...      1\n",
       "4  12409_10.txt  This picture doesn't have any big explosions o...      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_df = pd.read_csv(\"Test_data.csv\").drop(\"Unnamed: 0\",axis=1)\n",
    "testing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop words\n",
    "from nltk.corpus import stopwords\n",
    "en_stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive semantic words\n",
    "url = \"https://raw.githubusercontent.com/jeffreybreen/twitter-sentiment-analysis-tutorial-201107/master/data/opinion-lexicon-English/positive-words.txt\"\n",
    "r = requests.get(url)\n",
    "s=';;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\\n; \\n; Opinion Lexicon: Positive\\n;\\n; This file contains a list of POSITIVE opinion words (or sentiment words).\\n;\\n; This file and the papers can all be downloaded from \\n;    http://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html\\n;\\n; If you use this list, please cite one of the following two papers:\\n;\\n;   Minqing Hu and Bing Liu. \"Mining and Summarizing Customer Reviews.\" \\n;       Proceedings of the ACM SIGKDD International Conference on Knowledge \\n;       Discovery and Data Mining (KDD-2004), Aug 22-25, 2004, Seattle, \\n;       Washington, USA, \\n;   Bing Liu, Minqing Hu and Junsheng Cheng. \"Opinion Observer: Analyzing \\n;       and Comparing Opinions on the Web.\" Proceedings of the 14th \\n;       International World Wide Web conference (WWW-2005), May 10-14, \\n;       2005, Chiba, Japan.\\n;\\n; Notes: \\n;    1. The appearance of an opinion word in a sentence does not necessarily  \\n;       mean that the sentence expresses a positive or negative opinion. \\n;       See the paper below:\\n;\\n;       Bing Liu. \"Sentiment Analysis and Subjectivity.\" An chapter in \\n;          Handbook of Natural Language Processing, Second Edition, \\n;          (editors: N. Indurkhya and F. J. Damerau), 2010.\\n;\\n;    2. You will notice many misspelled words in the list. They are not \\n;       mistakes. They are included as these misspelled words appear \\n;       frequently in social media content. \\n;\\n;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;'\n",
    "pos_words = r.text[len(s)+2:]\n",
    "pos_words = pos_words.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative semantic words\n",
    "url = \"https://raw.githubusercontent.com/jeffreybreen/twitter-sentiment-analysis-tutorial-201107/master/data/opinion-lexicon-English/negative-words.txt\"\n",
    "r = requests.get(url)\n",
    "s=';;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\\n; \\n; Opinion Lexicon: Negative\\n;\\n; This file contains a list of NEGATIVE opinion words (or sentiment words).\\n;\\n; This file and the papers can all be downloaded from \\n;    http://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html\\n;\\n; If you use this list, please cite one of the following two papers:\\n;\\n;   Minqing Hu and Bing Liu. \"Mining and Summarizing Customer Reviews.\" \\n;       Proceedings of the ACM SIGKDD International Conference on Knowledge \\n;       Discovery and Data Mining (KDD-2004), Aug 22-25, 2004, Seattle, \\n;       Washington, USA, \\n;   Bing Liu, Minqing Hu and Junsheng Cheng. \"Opinion Observer: Analyzing \\n;       and Comparing Opinions on the Web.\" Proceedings of the 14th \\n;       International World Wide Web conference (WWW-2005), May 10-14, \\n;       2005, Chiba, Japan.\\n;\\n; Notes: \\n;    1. The appearance of an opinion word in a sentence does not necessarily  \\n;       mean that the sentence expresses a positive or negative opinion. \\n;       See the paper below:\\n;\\n;       Bing Liu. \"Sentiment Analysis and Subjectivity.\" An chapter in \\n;          Handbook of Natural Language Processing, Second Edition, \\n;          (editors: N. Indurkhya and F. J. Damerau), 2010.\\n;\\n;    2. You will notice many misspelled words in the list. They are not \\n;       mistakes. They are included as these misspelled words appear \\n;       frequently in social media content. \\n;\\n;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\\n\\n'\n",
    "neg_words = r.text[len(s):]\n",
    "neg_words = neg_words.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Engineering the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing reviews in training set\n",
    "words_train = (\n",
    "    training_df.Review.\n",
    "    str.lower().\n",
    "    str.replace(\"[^\\w\\s]\",\"\").\n",
    "    str.split()\n",
    ")\n",
    "bag_of_words_train = words_train.apply(Counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing reviews in test set\n",
    "words_test = (\n",
    "    testing_df.Review.\n",
    "    str.lower().\n",
    "    str.replace(\"[^\\w\\s]\",\"\").\n",
    "    str.split()\n",
    ")\n",
    "bag_of_words_test = words_test.apply(Counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stop words in training\n",
    "reviews_train = []\n",
    "for r in words_train:\n",
    "    good = []\n",
    "    for w in r:\n",
    "        if w not in en_stops:\n",
    "            good.append(w)\n",
    "    reviews_train.append(good)\n",
    "reviews_train = pd.Series(reviews_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stop words in test\n",
    "reviews_test = []\n",
    "for r in words_test:\n",
    "    good = []\n",
    "    for w in r:\n",
    "        if w not in en_stops:\n",
    "            good.append(w)\n",
    "    reviews_test.append(good)\n",
    "reviews_test = pd.Series(reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting positive and negative words in training set\n",
    "pos_set = set(pos_words)\n",
    "neg_set = set(neg_words)\n",
    "posc_train = []\n",
    "negc_train = []\n",
    "for r in reviews_train:\n",
    "    count_pos = len(pos_set.intersection(set(r)))\n",
    "    count_neg = len(neg_set.intersection(set(r)))\n",
    "    posc_train.append(count_pos)\n",
    "    negc_train.append(count_neg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting positive and negative words in test set\n",
    "pos_set = set(pos_words)\n",
    "neg_set = set(neg_words)\n",
    "posc_test = []\n",
    "negc_test = []\n",
    "for r in reviews_test:\n",
    "    count_pos = len(pos_set.intersection(set(r)))\n",
    "    count_neg = len(neg_set.intersection(set(r)))\n",
    "    posc_test.append(count_pos)\n",
    "    negc_test.append(count_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positive_counts</th>\n",
       "      <th>Negative_counts</th>\n",
       "      <th>ones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Positive_counts  Negative_counts  ones\n",
       "0                   23                6     1\n",
       "1                   13                3     1\n",
       "2                    8                3     1\n",
       "3                    2                2     1\n",
       "4                    7                1     1\n",
       "...                ...              ...   ...\n",
       "24995                3                3     1\n",
       "24996                2               13     1\n",
       "24997               12                9     1\n",
       "24998                3                9     1\n",
       "24999               14               27     1\n",
       "\n",
       "[25000 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = training_df.Label\n",
    "X_train = pd.DataFrame({\"Positive_counts\":posc_train, \"Negative_counts\":negc_train, \"ones\":[1]*len(y_train)})\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positive_counts</th>\n",
       "      <th>Negative_counts</th>\n",
       "      <th>ones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>9</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Positive_counts  Negative_counts  ones\n",
       "0                   13                6     1\n",
       "1                    2                0     1\n",
       "2                    7                8     1\n",
       "3                    6                3     1\n",
       "4                    6                2     1\n",
       "...                ...              ...   ...\n",
       "24995                7                4     1\n",
       "24996               11               17     1\n",
       "24997                4                9     1\n",
       "24998                9               34     1\n",
       "24999                7               10     1\n",
       "\n",
       "[25000 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = testing_df.Label\n",
    "X_test = pd.DataFrame({\"Positive_counts\":posc_test, \"Negative_counts\":negc_test, \"ones\":[1]*len(y_test)})\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized = X_train.divide(np.sqrt((X_train**2).sum()), axis=1)\n",
    "X_test_normalized = X_test.divide(np.sqrt((X_test**2).sum()), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "weight_norm1 = soft_SVM_training(X_train_normalized,\n",
    "                  y_train,\n",
    "                  25,\n",
    "                  np.array(X_train_normalized.mean()),\n",
    "                  10^-3,\n",
    "                  0.05,\n",
    "                  100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.73236, 'precision': 0.7295865939451427, 'recall': 0.7384}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Testing_soft_SVM(X_test_normalized,y_test,weight_norm1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "146266.4211133175\n"
     ]
    }
   ],
   "source": [
    "weight = soft_SVM_training(X_train,\n",
    "                  y_train,\n",
    "                  25,\n",
    "                  np.array(X_train.mean().T),\n",
    "                  10^-3,\n",
    "                  0.05,\n",
    "                  1000,\n",
    "                  128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.59468,\n",
       " 'precision': 0.5542914812606082,\n",
       " 'recall': 0.96664,\n",
       " 'f1': 0.7045686463162192}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Testing_soft_SVM(X_test,y_test,weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = X_train.copy()\n",
    "X_test2 = X_test.copy()\n",
    "y_train2 = y_train.copy()\n",
    "y_test2 = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2[\"Interaction_posc_negc\"] = X_train2.Positive_counts*X_train2.Negative_counts\n",
    "X_test2[\"Interaction_posc_negc\"] = X_test2.Positive_counts*X_test2.Negative_counts\n",
    "X_train2 = X_train2[[\"Positive_counts\",\"Negative_counts\",\"Interaction_posc_negc\",\"ones\"]]\n",
    "X_test2 = X_test2[[\"Positive_counts\",\"Negative_counts\",\"Interaction_posc_negc\",\"ones\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "weight2 = soft_SVM_training(X_train2,\n",
    "                  y_train2,\n",
    "                  25,\n",
    "                  np.array([X_train2.Positive_counts.mean(),X_train2.Negative_counts.mean(),X_train2.Interaction_posc_negc.mean(),1]),\n",
    "                  10^-3,\n",
    "                  0.05,\n",
    "                  100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.57704, 'precision': 0.9070160608622148, 'recall': 0.17168}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Testing_soft_SVM(X_test2,y_test2,weight2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2_normalized = X_train2.divide(np.sqrt((X_train2**2).sum()), axis=1)\n",
    "X_test2_normalized = X_test2.divide(np.sqrt((X_test2**2).sum()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "weight_norm2 = soft_SVM_training(X_train2_normalized,\n",
    "                  y_train,\n",
    "                  25,\n",
    "                  np.array(X_train2_normalized.mean()),\n",
    "                  10^-3,\n",
    "                  0.05,\n",
    "                  100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.73424, 'precision': 0.7319391634980988, 'recall': 0.7392}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Testing_soft_SVM(X_test2_normalized,y_test,weight_norm2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Squaring Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3 = X_train2.copy()\n",
    "X_test3 = X_test2.copy()\n",
    "y_train3 = y_train2.copy()\n",
    "y_test3 = y_test2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3[\"Positive_counts2\"] = X_train3.Positive_counts**2\n",
    "X_train3[\"Negative_counts2\"] = X_train3.Negative_counts**2\n",
    "X_test3[\"Positive_counts2\"] = X_test3.Positive_counts**2\n",
    "X_test3[\"Negative_counts2\"] = X_test3.Negative_counts**2\n",
    "X_train3.drop(\"ones\",axis=1,inplace=True)\n",
    "X_train3[\"ones\"] = [1]*25000\n",
    "X_test3.drop(\"ones\",axis=1,inplace=True)\n",
    "X_test3[\"ones\"] = [1]*25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positive_counts</th>\n",
       "      <th>Negative_counts</th>\n",
       "      <th>Interaction_posc_negc</th>\n",
       "      <th>Positive_counts2</th>\n",
       "      <th>Negative_counts2</th>\n",
       "      <th>ones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>78</td>\n",
       "      <td>169</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>49</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>49</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>187</td>\n",
       "      <td>121</td>\n",
       "      <td>289</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>16</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>9</td>\n",
       "      <td>34</td>\n",
       "      <td>306</td>\n",
       "      <td>81</td>\n",
       "      <td>1156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>70</td>\n",
       "      <td>49</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Positive_counts  Negative_counts  Interaction_posc_negc  \\\n",
       "0                   13                6                     78   \n",
       "1                    2                0                      0   \n",
       "2                    7                8                     56   \n",
       "3                    6                3                     18   \n",
       "4                    6                2                     12   \n",
       "...                ...              ...                    ...   \n",
       "24995                7                4                     28   \n",
       "24996               11               17                    187   \n",
       "24997                4                9                     36   \n",
       "24998                9               34                    306   \n",
       "24999                7               10                     70   \n",
       "\n",
       "       Positive_counts2  Negative_counts2  ones  \n",
       "0                   169                36     1  \n",
       "1                     4                 0     1  \n",
       "2                    49                64     1  \n",
       "3                    36                 9     1  \n",
       "4                    36                 4     1  \n",
       "...                 ...               ...   ...  \n",
       "24995                49                16     1  \n",
       "24996               121               289     1  \n",
       "24997                16                81     1  \n",
       "24998                81              1156     1  \n",
       "24999                49               100     1  \n",
       "\n",
       "[25000 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "2085603.508153232\n"
     ]
    }
   ],
   "source": [
    "weight3 = soft_SVM_training(X_train3,\n",
    "                  y_train3,\n",
    "                  25,\n",
    "                  np.array([X_train3.Positive_counts.mean(),\n",
    "                            X_train3.Negative_counts.mean(),\n",
    "                            X_train3.Interaction_posc_negc.mean(),\n",
    "                            X_train3.Positive_counts2.mean(),\n",
    "                            X_train3.Negative_counts2.mean(),\n",
    "                            1]),\n",
    "                  10^-3,\n",
    "                  0.05,\n",
    "                  1000,\n",
    "                128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP 11980\n",
      "TN 3348\n",
      "FP 9152\n",
      "FN 520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.61312,\n",
       " 'precision': 0.5669127389740678,\n",
       " 'recall': 0.9584,\n",
       " 'f1': 0.7124167459562323}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Testing_soft_SVM(X_test3,y_test3,weight3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEFORE THE STOCHASTIC\n",
    "# acc=0.68, pre = 0.851, recall=0.44"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3_normalized = X_train3.divide(np.sqrt((X_train3**2).sum()), axis=1)\n",
    "X_test3_normalized = X_test3.divide(np.sqrt((X_test3**2).sum()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "weight_norm3 = soft_SVM_training(X_train3_normalized,\n",
    "                  y_train,\n",
    "                  25,\n",
    "                  np.array(X_train3_normalized.mean()),\n",
    "                  10^-3,\n",
    "                  0.05,\n",
    "                  100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7342, 'precision': 0.732877257179222, 'recall': 0.73704}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Testing_soft_SVM(X_test3_normalized,y_test,weight_norm3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cubing Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train4 = X_train3.copy()\n",
    "X_test4 = X_test3.copy()\n",
    "y_train4 = y_train3.copy()\n",
    "y_test4 = y_test3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train4[\"Positive_counts3\"] = X_train4.Positive_counts**3\n",
    "X_train4[\"Negative_counts3\"] = X_train4.Negative_counts**3\n",
    "X_test4[\"Positive_counts3\"] = X_test4.Positive_counts**3\n",
    "X_test4[\"Negative_counts3\"] = X_test4.Negative_counts**3\n",
    "X_train4.drop(\"ones\",axis=1,inplace=True)\n",
    "X_train4[\"ones\"] = [1]*25000\n",
    "X_test4.drop(\"ones\",axis=1,inplace=True)\n",
    "X_test4[\"ones\"] = [1]*25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positive_counts</th>\n",
       "      <th>Negative_counts</th>\n",
       "      <th>Interaction_posc_negc</th>\n",
       "      <th>Positive_counts2</th>\n",
       "      <th>Negative_counts2</th>\n",
       "      <th>Positive_counts3</th>\n",
       "      <th>Negative_counts3</th>\n",
       "      <th>ones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>78</td>\n",
       "      <td>169</td>\n",
       "      <td>36</td>\n",
       "      <td>2197</td>\n",
       "      <td>216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>49</td>\n",
       "      <td>64</td>\n",
       "      <td>343</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>216</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>216</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>49</td>\n",
       "      <td>16</td>\n",
       "      <td>343</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>187</td>\n",
       "      <td>121</td>\n",
       "      <td>289</td>\n",
       "      <td>1331</td>\n",
       "      <td>4913</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>16</td>\n",
       "      <td>81</td>\n",
       "      <td>64</td>\n",
       "      <td>729</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>9</td>\n",
       "      <td>34</td>\n",
       "      <td>306</td>\n",
       "      <td>81</td>\n",
       "      <td>1156</td>\n",
       "      <td>729</td>\n",
       "      <td>39304</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>70</td>\n",
       "      <td>49</td>\n",
       "      <td>100</td>\n",
       "      <td>343</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Positive_counts  Negative_counts  Interaction_posc_negc  \\\n",
       "0                   13                6                     78   \n",
       "1                    2                0                      0   \n",
       "2                    7                8                     56   \n",
       "3                    6                3                     18   \n",
       "4                    6                2                     12   \n",
       "...                ...              ...                    ...   \n",
       "24995                7                4                     28   \n",
       "24996               11               17                    187   \n",
       "24997                4                9                     36   \n",
       "24998                9               34                    306   \n",
       "24999                7               10                     70   \n",
       "\n",
       "       Positive_counts2  Negative_counts2  Positive_counts3  Negative_counts3  \\\n",
       "0                   169                36              2197               216   \n",
       "1                     4                 0                 8                 0   \n",
       "2                    49                64               343               512   \n",
       "3                    36                 9               216                27   \n",
       "4                    36                 4               216                 8   \n",
       "...                 ...               ...               ...               ...   \n",
       "24995                49                16               343                64   \n",
       "24996               121               289              1331              4913   \n",
       "24997                16                81                64               729   \n",
       "24998                81              1156               729             39304   \n",
       "24999                49               100               343              1000   \n",
       "\n",
       "       ones  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  \n",
       "...     ...  \n",
       "24995     1  \n",
       "24996     1  \n",
       "24997     1  \n",
       "24998     1  \n",
       "24999     1  \n",
       "\n",
       "[25000 rows x 8 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "48961289.68442898\n"
     ]
    }
   ],
   "source": [
    "weight4 = soft_SVM_training(X_train4,\n",
    "                  y_train4,\n",
    "                  25,\n",
    "                  np.array(X_train4.mean().T),\n",
    "                  10^-3,\n",
    "                  0.05,\n",
    "                  1000,\n",
    "                    128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP 0\n",
      "TN 12500\n",
      "FP 0\n",
      "FN 12500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5, 'recall': 0.0}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Testing_soft_SVM(X_test4,y_test4,weight4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train4_normalized = X_train4.divide(np.sqrt((X_train4**2).sum()), axis=1)\n",
    "X_test4_normalized = X_test4.divide(np.sqrt((X_test4**2).sum()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "weight_norm4 = soft_SVM_training(X_train4_normalized,\n",
    "                  y_train,\n",
    "                  1,\n",
    "                  np.array(X_train4_normalized.mean()),\n",
    "                  10^-3,\n",
    "                  0.05,\n",
    "                  100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.72424, 'precision': 0.6925931015528377, 'recall': 0.8064}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Testing_soft_SVM(X_test4_normalized,y_test,weight_norm4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sq = X_train4[[\"Positive_counts2\",\"Negative_counts2\",\"ones\"]]\n",
    "X_test_sq = X_test4[[\"Positive_counts2\",\"Negative_counts2\",\"ones\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "164661.74809410312\n"
     ]
    }
   ],
   "source": [
    "weight_sq = soft_SVM_training(X_train_sq,\n",
    "                  y_train,\n",
    "                  5,\n",
    "                  np.array(X_train_sq.mean()),\n",
    "                  10^-3,\n",
    "                  0.05,\n",
    "                  1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.72648, 'precision': 0.7787514769594328, 'recall': 0.63272}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Testing_soft_SVM(X_test_sq,y_test,weight_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.91935693],\n",
       "       [0.91935693, 1.        ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(X_train4.Positive_counts, X_train4.Positive_counts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(list(reviews.apply(Counter)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train.Positive_counts, X_train.Negative_counts, c=y_train, cmap=plt.cm.Set1,\n",
    "            edgecolor='k',alpha=0.05)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Soft-SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_comp(X,y,C,w0):\n",
    "    summands_of_X = X[X.dot(w0) * y <= 1]\n",
    "    summands_of_y = y[summands_of_X.index]\n",
    "    Y = []\n",
    "    for i in range(summands_of_X.shape[1]):\n",
    "        Y.append(list(summands_of_y))\n",
    "    summands = -1*np.multiply(pd.DataFrame(Y).values.T,summands_of_X)\n",
    "    gradient = w0 + C*summands.sum()\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_SVM_training(X,y,C,w0,eps,lr,n):\n",
    "    # X is training data\n",
    "    # y is labels\n",
    "    # C is penalty of how hard to be\n",
    "    # w is initial weights vector (np.array)\n",
    "    # eps is convergence criterion\n",
    "    # lr is learning rate\n",
    "    \n",
    "    # Computing gradient of L\n",
    "    i = 0\n",
    "    gradw = gradient_comp(X,y,C,w0)\n",
    "    w1 = w0 - lr*gradw\n",
    "    while(np.linalg.norm(w0-w1) > eps):\n",
    "        w0 = w1\n",
    "        w1 = w0 - lr*gradient_comp(X,y,C,w0)\n",
    "        i = i + 1\n",
    "        print(i)\n",
    "        if i == n:\n",
    "            break\n",
    "    return w1\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = soft_SVM_training(X_train,\n",
    "                  y_train,\n",
    "                  1,\n",
    "                  np.array([X_train.Positive_counts.mean(),X_train.Negative_counts.mean(),1]),\n",
    "                  10^-3,\n",
    "                  0.05,\n",
    "                  100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_with_classifier(X,y,w):\n",
    "    # plot points\n",
    "    plt.clf()\n",
    "    plt.scatter(X.loc[:, \"Positive_counts\"], X.loc[:, \"Negative_counts\"], c=y, cmap=plt.cm.Set1, edgecolor='k')\n",
    "\n",
    "    # draw hyperplane\n",
    "    xrange = np.linspace(np.min(X.loc[:, \"Positive_counts\"]),X.loc[:, \"Negative_counts\"])\n",
    "    yrange = -(w[0]*xrange+w[2])/w[1]\n",
    "    plt.plot(xrange,yrange,'red')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_with_classifier(X_train,y_train,weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_set = set(pos_words)\n",
    "neg_set = set(neg_words)\n",
    "sentiment_words = []\n",
    "for r in reviews:\n",
    "    positives = list(pos_set.intersection(set(r)))\n",
    "    negatives = list(neg_set.intersection(set(r)))\n",
    "    sentiment_words.append(positives+negatives)\n",
    "sentiment_words = pd.Series(sentiment_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = pd.DataFrame(list(sentiment_words.apply(Counter)))\n",
    "tf = tf.fillna(0)\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docFreq = (tf > 0).sum(axis=0)\n",
    "idf = np.log(len(tf) / docFreq)\n",
    "tf_idf = tf*idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf_idf\n",
    "X_train[\"ones\"] = [1]*len(tf_idf)\n",
    "y_train = training_df.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = soft_SVM_training(X_train,\n",
    "                  y_train,\n",
    "                  1,\n",
    "                  np.array([0]*X_train.shape[1]),\n",
    "                  10^-3,\n",
    "                  0.01,\n",
    "                  100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"tf_idf_model.npy\",weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_model = np.load(\"tf_idf_model.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"Test_data.csv\").drop(\"Unnamed: 0\",axis=1)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = (\n",
    "    test_df.Review.\n",
    "    str.lower().\n",
    "    str.replace(\"[^\\w\\s]\",\"\").\n",
    "    str.split()\n",
    ")\n",
    "bag_of_words = words.apply(Counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "en_stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/jeffreybreen/twitter-sentiment-analysis-tutorial-201107/master/data/opinion-lexicon-English/positive-words.txt\"\n",
    "r = requests.get(url)\n",
    "s=';;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\\n; \\n; Opinion Lexicon: Positive\\n;\\n; This file contains a list of POSITIVE opinion words (or sentiment words).\\n;\\n; This file and the papers can all be downloaded from \\n;    http://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html\\n;\\n; If you use this list, please cite one of the following two papers:\\n;\\n;   Minqing Hu and Bing Liu. \"Mining and Summarizing Customer Reviews.\" \\n;       Proceedings of the ACM SIGKDD International Conference on Knowledge \\n;       Discovery and Data Mining (KDD-2004), Aug 22-25, 2004, Seattle, \\n;       Washington, USA, \\n;   Bing Liu, Minqing Hu and Junsheng Cheng. \"Opinion Observer: Analyzing \\n;       and Comparing Opinions on the Web.\" Proceedings of the 14th \\n;       International World Wide Web conference (WWW-2005), May 10-14, \\n;       2005, Chiba, Japan.\\n;\\n; Notes: \\n;    1. The appearance of an opinion word in a sentence does not necessarily  \\n;       mean that the sentence expresses a positive or negative opinion. \\n;       See the paper below:\\n;\\n;       Bing Liu. \"Sentiment Analysis and Subjectivity.\" An chapter in \\n;          Handbook of Natural Language Processing, Second Edition, \\n;          (editors: N. Indurkhya and F. J. Damerau), 2010.\\n;\\n;    2. You will notice many misspelled words in the list. They are not \\n;       mistakes. They are included as these misspelled words appear \\n;       frequently in social media content. \\n;\\n;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;'\n",
    "pos_words = r.text[len(s)+2:]\n",
    "pos_words = pos_words.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/jeffreybreen/twitter-sentiment-analysis-tutorial-201107/master/data/opinion-lexicon-English/negative-words.txt\"\n",
    "r = requests.get(url)\n",
    "s=';;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\\n; \\n; Opinion Lexicon: Negative\\n;\\n; This file contains a list of NEGATIVE opinion words (or sentiment words).\\n;\\n; This file and the papers can all be downloaded from \\n;    http://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html\\n;\\n; If you use this list, please cite one of the following two papers:\\n;\\n;   Minqing Hu and Bing Liu. \"Mining and Summarizing Customer Reviews.\" \\n;       Proceedings of the ACM SIGKDD International Conference on Knowledge \\n;       Discovery and Data Mining (KDD-2004), Aug 22-25, 2004, Seattle, \\n;       Washington, USA, \\n;   Bing Liu, Minqing Hu and Junsheng Cheng. \"Opinion Observer: Analyzing \\n;       and Comparing Opinions on the Web.\" Proceedings of the 14th \\n;       International World Wide Web conference (WWW-2005), May 10-14, \\n;       2005, Chiba, Japan.\\n;\\n; Notes: \\n;    1. The appearance of an opinion word in a sentence does not necessarily  \\n;       mean that the sentence expresses a positive or negative opinion. \\n;       See the paper below:\\n;\\n;       Bing Liu. \"Sentiment Analysis and Subjectivity.\" An chapter in \\n;          Handbook of Natural Language Processing, Second Edition, \\n;          (editors: N. Indurkhya and F. J. Damerau), 2010.\\n;\\n;    2. You will notice many misspelled words in the list. They are not \\n;       mistakes. They are included as these misspelled words appear \\n;       frequently in social media content. \\n;\\n;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\\n\\n'\n",
    "neg_words = r.text[len(s):]\n",
    "neg_words = neg_words.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "for r in words:\n",
    "    good = []\n",
    "    for w in r:\n",
    "        if w not in en_stops:\n",
    "            good.append(w)\n",
    "    reviews.append(good)\n",
    "reviews = pd.Series(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = set(all_words)\n",
    "sentiment_words = []\n",
    "for r in reviews:\n",
    "    sentiment_words.append(list(sents.intersection(set(r))))\n",
    "sentiment_words = pd.Series(sentiment_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = pd.DataFrame(list(sentiment_words.apply(Counter)))\n",
    "tf = tf.fillna(0)\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docFreq = (tf > 0).sum(axis=0)\n",
    "idf = np.log(len(tf) / docFreq)\n",
    "tf_idf = tf*idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tf_idf\n",
    "X_test[\"ones\"] = [1]*len(tf_idf)\n",
    "y_test = test_df.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
