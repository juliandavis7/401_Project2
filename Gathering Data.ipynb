{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pos',\n",
       " 'urls_neg.txt',\n",
       " 'urls_pos.txt',\n",
       " 'urls_unsup.txt',\n",
       " 'neg',\n",
       " 'labeledBow.feat',\n",
       " 'unsupBow.feat',\n",
       " 'unsup']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maindir = os.getcwd()\n",
    "os.chdir(\"/../../datasets/aclImdb/train\")\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_neg_urls = open(\"urls_neg.txt\", \"r\")\n",
    "# neg_urls = []\n",
    "# for i in f_neg_urls:\n",
    "#     neg_urls.append(i.strip(\"\\n\"))\n",
    "#     f_neg_urls = open(\"urls_neg.txt\", \"r\")\n",
    "# (f_neg_urls).close()\n",
    "\n",
    "# f_pos_urls = open(\"urls_pos.txt\", \"r\")\n",
    "# pos_urls = []\n",
    "# for i in f_pos_urls:\n",
    "#     pos_urls.append(i.strip(\"\\n\"))\n",
    "# (f_pos_urls).close()  \n",
    "\n",
    "# f_labels = open(\"labeledBow.feat\",'r')\n",
    "# labels_dirty = f_labels.read().split(\" \")\n",
    "# labels = []\n",
    "# for i in labels_dirty:\n",
    "#     labels.append(i.replace(\"\\n\",''))\n",
    "# (f_labels).close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_files = os.listdir()\n",
    "pos_reviews = []\n",
    "for i in pos_files:\n",
    "    f = open(i,'r')\n",
    "    rev = f.read()\n",
    "    pos_reviews.append(rev)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../neg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_files = os.listdir()\n",
    "neg_reviews = []\n",
    "for i in neg_files:\n",
    "    f = open(i,'r')\n",
    "    rev = f.read()\n",
    "    neg_reviews.append(rev)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = pd.DataFrame({\"File\":pos_files,\"Review\":pos_reviews,\"Label\":[1]*len(pos_files)})\n",
    "df_neg = pd.DataFrame({\"File\":neg_files,\"Review\":neg_reviews,\"Label\":[-1]*len(neg_files)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_pos, df_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2893_10.txt</td>\n",
       "      <td>Walt Disney's CINDERELLA takes a story everybo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7944_9.txt</td>\n",
       "      <td>Have you ever, or do you have, a pet who's bee...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11725_10.txt</td>\n",
       "      <td>I suck at gratuitous Boob references, so i'm j...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1587_10.txt</td>\n",
       "      <td>Does anyone know, where I can see or download ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10297_8.txt</td>\n",
       "      <td>Well not actually. This movie is very entertai...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           File                                             Review  Label\n",
       "0   2893_10.txt  Walt Disney's CINDERELLA takes a story everybo...      1\n",
       "1    7944_9.txt  Have you ever, or do you have, a pet who's bee...      1\n",
       "2  11725_10.txt  I suck at gratuitous Boob references, so i'm j...      1\n",
       "3   1587_10.txt  Does anyone know, where I can see or download ...      1\n",
       "4   10297_8.txt  Well not actually. This movie is very entertai...      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../../test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_neg_urls = open(\"urls_neg.txt\", \"r\")\n",
    "# neg_urls = []\n",
    "# for i in f_neg_urls:\n",
    "#     neg_urls.append(i.strip(\"\\n\"))\n",
    "#     f_neg_urls = open(\"urls_neg.txt\", \"r\")\n",
    "# (f_neg_urls).close()\n",
    "\n",
    "# f_pos_urls = open(\"urls_pos.txt\", \"r\")\n",
    "# pos_urls = []\n",
    "# for i in f_pos_urls:\n",
    "#     pos_urls.append(i.strip(\"\\n\"))\n",
    "# (f_pos_urls).close()  \n",
    "\n",
    "f_labels = open(\"labeledBow.feat\",'r')\n",
    "labels_dirty = f_labels.read().split(\" \")\n",
    "labels = []\n",
    "for i in labels_dirty:\n",
    "    labels.append(i.replace(\"\\n\",''))\n",
    "(f_labels).close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_files = os.listdir()\n",
    "pos_reviews = []\n",
    "for i in pos_files:\n",
    "    f = open(i,'r')\n",
    "    rev = f.read()\n",
    "    pos_reviews.append(rev)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../neg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_files = os.listdir()\n",
    "neg_reviews = []\n",
    "for i in neg_files:\n",
    "    f = open(i,'r')\n",
    "    rev = f.read()\n",
    "    neg_reviews.append(rev)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = pd.DataFrame({\"File\":pos_files,\"Review\":pos_reviews,\"Label\":[1]*len(pos_files)})\n",
    "df_neg = pd.DataFrame({\"File\":neg_files,\"Review\":neg_reviews,\"Label\":[-1]*len(neg_files)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.concat([df_pos, df_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2893_10.txt</td>\n",
       "      <td>\"Rush in Rio\" is, no doubt, one of the most ex...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8705_10.txt</td>\n",
       "      <td>I have seen a number of horror movies to know ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11725_10.txt</td>\n",
       "      <td>I'm a fan of B grade 80s films in which the he...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9859_8.txt</td>\n",
       "      <td>I think that Pierre LÃ©aud, or his character, t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12409_10.txt</td>\n",
       "      <td>This picture doesn't have any big explosions o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           File                                             Review  Label\n",
       "0   2893_10.txt  \"Rush in Rio\" is, no doubt, one of the most ex...      1\n",
       "1   8705_10.txt  I have seen a number of horror movies to know ...      1\n",
       "2  11725_10.txt  I'm a fan of B grade 80s films in which the he...      1\n",
       "3    9859_8.txt  I think that Pierre LÃ©aud, or his character, t...      1\n",
       "4  12409_10.txt  This picture doesn't have any big explosions o...      1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Set for Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop words\n",
    "from nltk.corpus import stopwords\n",
    "en_stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive semantic words\n",
    "url = \"https://raw.githubusercontent.com/jeffreybreen/twitter-sentiment-analysis-tutorial-201107/master/data/opinion-lexicon-English/positive-words.txt\"\n",
    "r = requests.get(url)\n",
    "s=';;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\\n; \\n; Opinion Lexicon: Positive\\n;\\n; This file contains a list of POSITIVE opinion words (or sentiment words).\\n;\\n; This file and the papers can all be downloaded from \\n;    http://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html\\n;\\n; If you use this list, please cite one of the following two papers:\\n;\\n;   Minqing Hu and Bing Liu. \"Mining and Summarizing Customer Reviews.\" \\n;       Proceedings of the ACM SIGKDD International Conference on Knowledge \\n;       Discovery and Data Mining (KDD-2004), Aug 22-25, 2004, Seattle, \\n;       Washington, USA, \\n;   Bing Liu, Minqing Hu and Junsheng Cheng. \"Opinion Observer: Analyzing \\n;       and Comparing Opinions on the Web.\" Proceedings of the 14th \\n;       International World Wide Web conference (WWW-2005), May 10-14, \\n;       2005, Chiba, Japan.\\n;\\n; Notes: \\n;    1. The appearance of an opinion word in a sentence does not necessarily  \\n;       mean that the sentence expresses a positive or negative opinion. \\n;       See the paper below:\\n;\\n;       Bing Liu. \"Sentiment Analysis and Subjectivity.\" An chapter in \\n;          Handbook of Natural Language Processing, Second Edition, \\n;          (editors: N. Indurkhya and F. J. Damerau), 2010.\\n;\\n;    2. You will notice many misspelled words in the list. They are not \\n;       mistakes. They are included as these misspelled words appear \\n;       frequently in social media content. \\n;\\n;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;'\n",
    "pos_words = r.text[len(s)+2:]\n",
    "pos_words = pos_words.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative semantic words\n",
    "url = \"https://raw.githubusercontent.com/jeffreybreen/twitter-sentiment-analysis-tutorial-201107/master/data/opinion-lexicon-English/negative-words.txt\"\n",
    "r = requests.get(url)\n",
    "s=';;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\\n; \\n; Opinion Lexicon: Negative\\n;\\n; This file contains a list of NEGATIVE opinion words (or sentiment words).\\n;\\n; This file and the papers can all be downloaded from \\n;    http://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html\\n;\\n; If you use this list, please cite one of the following two papers:\\n;\\n;   Minqing Hu and Bing Liu. \"Mining and Summarizing Customer Reviews.\" \\n;       Proceedings of the ACM SIGKDD International Conference on Knowledge \\n;       Discovery and Data Mining (KDD-2004), Aug 22-25, 2004, Seattle, \\n;       Washington, USA, \\n;   Bing Liu, Minqing Hu and Junsheng Cheng. \"Opinion Observer: Analyzing \\n;       and Comparing Opinions on the Web.\" Proceedings of the 14th \\n;       International World Wide Web conference (WWW-2005), May 10-14, \\n;       2005, Chiba, Japan.\\n;\\n; Notes: \\n;    1. The appearance of an opinion word in a sentence does not necessarily  \\n;       mean that the sentence expresses a positive or negative opinion. \\n;       See the paper below:\\n;\\n;       Bing Liu. \"Sentiment Analysis and Subjectivity.\" An chapter in \\n;          Handbook of Natural Language Processing, Second Edition, \\n;          (editors: N. Indurkhya and F. J. Damerau), 2010.\\n;\\n;    2. You will notice many misspelled words in the list. They are not \\n;       mistakes. They are included as these misspelled words appear \\n;       frequently in social media content. \\n;\\n;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\\n\\n'\n",
    "neg_words = r.text[len(s):]\n",
    "neg_words = neg_words.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engineering the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing reviews in training set\n",
    "words_train = (\n",
    "    df_train.Review.\n",
    "    str.lower().\n",
    "    str.replace(\"[^\\w\\s]\",\"\").\n",
    "    str.split()\n",
    ")\n",
    "bag_of_words_train = words_train.apply(Counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing reviews in test set\n",
    "words_test = (\n",
    "    df_test.Review.\n",
    "    str.lower().\n",
    "    str.replace(\"[^\\w\\s]\",\"\").\n",
    "    str.split()\n",
    ")\n",
    "bag_of_words_test = words_test.apply(Counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stop words in train\n",
    "reviews_train = []\n",
    "for r in words_train:\n",
    "    good = []\n",
    "    for w in r:\n",
    "        if w not in en_stops:\n",
    "            good.append(w)\n",
    "    reviews_train.append(good)\n",
    "reviews_train = pd.Series(reviews_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stop words in test\n",
    "reviews_test = []\n",
    "for r in words_test:\n",
    "    good = []\n",
    "    for w in r:\n",
    "        if w not in en_stops:\n",
    "            good.append(w)\n",
    "    reviews_test.append(good)\n",
    "reviews_test = pd.Series(reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting positive and negative words in training set\n",
    "pos_set = set(pos_words)\n",
    "neg_set = set(neg_words)\n",
    "posc_train = []\n",
    "negc_train = []\n",
    "for r in reviews_train:\n",
    "    count_pos = len(pos_set.intersection(set(r)))\n",
    "    count_neg = len(neg_set.intersection(set(r)))\n",
    "    posc_train.append(count_pos)\n",
    "    negc_train.append(count_neg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting positive and negative words in test set\n",
    "pos_set = set(pos_words)\n",
    "neg_set = set(neg_words)\n",
    "posc_test = []\n",
    "negc_test = []\n",
    "for r in reviews_test:\n",
    "    count_pos = len(pos_set.intersection(set(r)))\n",
    "    count_neg = len(neg_set.intersection(set(r)))\n",
    "    posc_test.append(count_pos)\n",
    "    negc_test.append(count_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame({\"Positive_counts\":posc_train, \n",
    "                         \"Negative_counts\":negc_train, \n",
    "                         \"Label\": df_train.Label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame({\"Positive_counts\":posc_test, \n",
    "                        \"Negative_counts\":negc_test,\n",
    "                        \"Label\": df_test.Label})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(maindir)\n",
    "df_train.to_csv(\"train1.csv\")\n",
    "df_test.to_csv(\"test1.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
