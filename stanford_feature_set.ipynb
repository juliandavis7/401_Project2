{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the Stanford Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "maindir = os.getcwd()\n",
    "os.chdir(\"/../../datasets/aclImdb/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_f = open(\"imdb.vocab\",'r')\n",
    "vocab = voc_f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exp_f = open(\"imdbEr.txt\",'r')\n",
    "EV = Exp_f.read().split(\"\\n\")[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab</th>\n",
       "      <th>expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>0.0490972013402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "      <td>0.201363575849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>0.0333946807184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>0.099837669572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>-0.0790210365788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89522</th>\n",
       "      <td>copywrite</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89523</th>\n",
       "      <td>artbox</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89524</th>\n",
       "      <td>kinky-sex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89525</th>\n",
       "      <td>urrrghhh</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89526</th>\n",
       "      <td>investigator-like</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89527 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   vocab          expected\n",
       "0                    the   0.0490972013402\n",
       "1                    and    0.201363575849\n",
       "2                      a   0.0333946807184\n",
       "3                     of    0.099837669572\n",
       "4                     to  -0.0790210365788\n",
       "...                  ...               ...\n",
       "89522          copywrite                 0\n",
       "89523             artbox                 0\n",
       "89524          kinky-sex                 0\n",
       "89525           urrrghhh                 0\n",
       "89526  investigator-like                 0\n",
       "\n",
       "[89527 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabInfo = pd.DataFrame({\"vocab\":vocab,\"expected\":EV})\n",
    "vocabInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab</th>\n",
       "      <th>expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>movie</td>\n",
       "      <td>0.246354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>film</td>\n",
       "      <td>0.147886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>one</td>\n",
       "      <td>0.087114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>!</td>\n",
       "      <td>0.134839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>like</td>\n",
       "      <td>0.280548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89522</th>\n",
       "      <td>copywrite</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89523</th>\n",
       "      <td>artbox</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89524</th>\n",
       "      <td>kinky-sex</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89525</th>\n",
       "      <td>urrrghhh</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89526</th>\n",
       "      <td>investigator-like</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89356 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   vocab  expected\n",
       "15                 movie  0.246354\n",
       "17                  film  0.147886\n",
       "26                   one  0.087114\n",
       "27                     !  0.134839\n",
       "36                  like  0.280548\n",
       "...                  ...       ...\n",
       "89522          copywrite  0.000000\n",
       "89523             artbox  0.000000\n",
       "89524          kinky-sex  0.000000\n",
       "89525           urrrghhh  0.000000\n",
       "89526  investigator-like  0.000000\n",
       "\n",
       "[89356 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_stops = set(stopwords.words('english'))\n",
    "\n",
    "vocabInfo = vocabInfo[~ vocabInfo[\"vocab\"].isin(en_stops)]\n",
    "vocabInfo[\"expected\"] = abs(vocabInfo[\"expected\"].astype(float))\n",
    "vocabInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab</th>\n",
       "      <th>expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54867</th>\n",
       "      <td>pelswick</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33943</th>\n",
       "      <td>magorian</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67306</th>\n",
       "      <td>subspace</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35092</th>\n",
       "      <td>jgar</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58224</th>\n",
       "      <td>buh</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81702</th>\n",
       "      <td>danira</td>\n",
       "      <td>2.267657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61418</th>\n",
       "      <td>ecclesiastical</td>\n",
       "      <td>2.267421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40382</th>\n",
       "      <td>grey-haired</td>\n",
       "      <td>2.267421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44828</th>\n",
       "      <td>irland</td>\n",
       "      <td>2.267421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36139</th>\n",
       "      <td>two-shoes</td>\n",
       "      <td>2.267421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4468 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                vocab  expected\n",
       "54867        pelswick  4.500000\n",
       "33943        magorian  4.500000\n",
       "67306        subspace  4.500000\n",
       "35092            jgar  4.500000\n",
       "58224             buh  4.500000\n",
       "...               ...       ...\n",
       "81702          danira  2.267657\n",
       "61418  ecclesiastical  2.267421\n",
       "40382     grey-haired  2.267421\n",
       "44828          irland  2.267421\n",
       "36139       two-shoes  2.267421\n",
       "\n",
       "[4468 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabInfo.sort_values(by=\"expected\",ascending=False)[:round(len(vocabInfo)*0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30896"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sub = (vocabInfo[vocabInfo[\"expected\"] <= 2].sort_values(by=\"expected\"))\n",
    "#sub_vocab = list(sub)\n",
    "\n",
    "allowed_word_types = [\"J\"]\n",
    "\n",
    "adjectives = []\n",
    "# parts of speech tagging for each word \n",
    "pos = nltk.pos_tag(list(vocabInfo[\"vocab\"]))\n",
    "    \n",
    "# make a list of  all adjectives identified by the allowed word types list above\n",
    "for w in pos:\n",
    "    if w[1][0] in allowed_word_types:\n",
    "        adjectives.append(w[0].lower())   \n",
    "\n",
    "#reduced_vocab = pd.Series(reduced_vocab)\n",
    "#reduced_vocab = reduced_vocab.sample(n=round(len(reduced_vocab)*0.3),random_state=1)\n",
    "len(adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive semantic words\n",
    "url = \"https://raw.githubusercontent.com/jeffreybreen/twitter-sentiment-analysis-tutorial-201107/master/data/opinion-lexicon-English/positive-words.txt\"\n",
    "r = requests.get(url)\n",
    "s=';;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\\n; \\n; Opinion Lexicon: Positive\\n;\\n; This file contains a list of POSITIVE opinion words (or sentiment words).\\n;\\n; This file and the papers can all be downloaded from \\n;    http://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html\\n;\\n; If you use this list, please cite one of the following two papers:\\n;\\n;   Minqing Hu and Bing Liu. \"Mining and Summarizing Customer Reviews.\" \\n;       Proceedings of the ACM SIGKDD International Conference on Knowledge \\n;       Discovery and Data Mining (KDD-2004), Aug 22-25, 2004, Seattle, \\n;       Washington, USA, \\n;   Bing Liu, Minqing Hu and Junsheng Cheng. \"Opinion Observer: Analyzing \\n;       and Comparing Opinions on the Web.\" Proceedings of the 14th \\n;       International World Wide Web conference (WWW-2005), May 10-14, \\n;       2005, Chiba, Japan.\\n;\\n; Notes: \\n;    1. The appearance of an opinion word in a sentence does not necessarily  \\n;       mean that the sentence expresses a positive or negative opinion. \\n;       See the paper below:\\n;\\n;       Bing Liu. \"Sentiment Analysis and Subjectivity.\" An chapter in \\n;          Handbook of Natural Language Processing, Second Edition, \\n;          (editors: N. Indurkhya and F. J. Damerau), 2010.\\n;\\n;    2. You will notice many misspelled words in the list. They are not \\n;       mistakes. They are included as these misspelled words appear \\n;       frequently in social media content. \\n;\\n;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;'\n",
    "pos_words = r.text[len(s)+2:]\n",
    "pos_words = pos_words.split(\"\\n\")\n",
    "\n",
    "# Negative semantic words\n",
    "url = \"https://raw.githubusercontent.com/jeffreybreen/twitter-sentiment-analysis-tutorial-201107/master/data/opinion-lexicon-English/negative-words.txt\"\n",
    "r = requests.get(url)\n",
    "s=';;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\\n; \\n; Opinion Lexicon: Negative\\n;\\n; This file contains a list of NEGATIVE opinion words (or sentiment words).\\n;\\n; This file and the papers can all be downloaded from \\n;    http://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html\\n;\\n; If you use this list, please cite one of the following two papers:\\n;\\n;   Minqing Hu and Bing Liu. \"Mining and Summarizing Customer Reviews.\" \\n;       Proceedings of the ACM SIGKDD International Conference on Knowledge \\n;       Discovery and Data Mining (KDD-2004), Aug 22-25, 2004, Seattle, \\n;       Washington, USA, \\n;   Bing Liu, Minqing Hu and Junsheng Cheng. \"Opinion Observer: Analyzing \\n;       and Comparing Opinions on the Web.\" Proceedings of the 14th \\n;       International World Wide Web conference (WWW-2005), May 10-14, \\n;       2005, Chiba, Japan.\\n;\\n; Notes: \\n;    1. The appearance of an opinion word in a sentence does not necessarily  \\n;       mean that the sentence expresses a positive or negative opinion. \\n;       See the paper below:\\n;\\n;       Bing Liu. \"Sentiment Analysis and Subjectivity.\" An chapter in \\n;          Handbook of Natural Language Processing, Second Edition, \\n;          (editors: N. Indurkhya and F. J. Damerau), 2010.\\n;\\n;    2. You will notice many misspelled words in the list. They are not \\n;       mistakes. They are included as these misspelled words appear \\n;       frequently in social media content. \\n;\\n;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\\n\\n'\n",
    "neg_words = r.text[len(s):]\n",
    "neg_words = neg_words.split(\"\\n\")\n",
    "\n",
    "all_words = pos_words + neg_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1900"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all adjectives that have a \"good\" or \"bad\" association\n",
    "word_features = []\n",
    "for w in adjectives:\n",
    "    if w in all_words:\n",
    "        word_features.append(w)\n",
    "len(word_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Derived Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(maindir)\n",
    "\n",
    "df_train = pd.read_csv(\"reviews_train.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "df_test = pd.read_csv(\"reviews_test.csv\").drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create a dictionary of features for each review in the list document.\n",
    "# The keys are the words in word_features \n",
    "# The values of each key are either true or false for wether that feature appears in the review or not\n",
    "def find_features(document):\n",
    "    words = word_tokenize(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "# Creating features for each review\n",
    "featuresets = []\n",
    "\n",
    "for i, row in df_train.iterrows():\n",
    "    featuresets.append((find_features(row[\"Review\"]), row[\"Label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>good</th>\n",
       "      <th>bad</th>\n",
       "      <th>great</th>\n",
       "      <th>best</th>\n",
       "      <th>better</th>\n",
       "      <th>funny</th>\n",
       "      <th>enough</th>\n",
       "      <th>right</th>\n",
       "      <th>worst</th>\n",
       "      <th>hard</th>\n",
       "      <th>...</th>\n",
       "      <th>halcyon</th>\n",
       "      <th>swiftness</th>\n",
       "      <th>semi-retarded</th>\n",
       "      <th>inviolable</th>\n",
       "      <th>impolite</th>\n",
       "      <th>unlicensed</th>\n",
       "      <th>unconstitutional</th>\n",
       "      <th>uneasily</th>\n",
       "      <th>last-ditch</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1901 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   good  bad  great  best  better  funny  enough  right  worst  hard  ...  \\\n",
       "0     0    0      0     0       0      0       0      0      0     0  ...   \n",
       "1     0    0      0     0       1      0       0      0      0     0  ...   \n",
       "2     0    0      1     0       0      0       0      0      0     0  ...   \n",
       "3     0    0      0     0       0      0       0      0      0     0  ...   \n",
       "4     1    0      1     0       0      1       0      0      0     0  ...   \n",
       "\n",
       "   halcyon  swiftness  semi-retarded  inviolable  impolite  unlicensed  \\\n",
       "0        0          0              0           0         0           0   \n",
       "1        0          0              0           0         0           0   \n",
       "2        0          0              0           0         0           0   \n",
       "3        0          0              0           0         0           0   \n",
       "4        0          0              0           0         0           0   \n",
       "\n",
       "   unconstitutional  uneasily  last-ditch  Label  \n",
       "0                 0         0           0      1  \n",
       "1                 0         0           0      1  \n",
       "2                 0         0           0      1  \n",
       "3                 0         0           0      1  \n",
       "4                 0         0           0      1  \n",
       "\n",
       "[5 rows x 1901 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(featuresets)\n",
    "df_train = pd.json_normalize(df[0])\n",
    "df_train = df_train.astype(int)\n",
    "df_train[\"Label\"] = df[1]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>good</th>\n",
       "      <th>bad</th>\n",
       "      <th>great</th>\n",
       "      <th>best</th>\n",
       "      <th>better</th>\n",
       "      <th>funny</th>\n",
       "      <th>enough</th>\n",
       "      <th>right</th>\n",
       "      <th>worst</th>\n",
       "      <th>hard</th>\n",
       "      <th>...</th>\n",
       "      <th>halcyon</th>\n",
       "      <th>swiftness</th>\n",
       "      <th>semi-retarded</th>\n",
       "      <th>inviolable</th>\n",
       "      <th>impolite</th>\n",
       "      <th>unlicensed</th>\n",
       "      <th>unconstitutional</th>\n",
       "      <th>uneasily</th>\n",
       "      <th>last-ditch</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1901 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   good  bad  great  best  better  funny  enough  right  worst  hard  ...  \\\n",
       "0     0    0      0     0       0      0       0      0      0     0  ...   \n",
       "1     0    0      0     0       1      0       0      0      0     0  ...   \n",
       "2     0    0      1     0       0      0       0      0      0     0  ...   \n",
       "3     0    0      0     0       0      0       0      0      0     0  ...   \n",
       "4     1    0      1     0       0      1       0      0      0     0  ...   \n",
       "\n",
       "   halcyon  swiftness  semi-retarded  inviolable  impolite  unlicensed  \\\n",
       "0        0          0              0           0         0           0   \n",
       "1        0          0              0           0         0           0   \n",
       "2        0          0              0           0         0           0   \n",
       "3        0          0              0           0         0           0   \n",
       "4        0          0              0           0         0           0   \n",
       "\n",
       "   unconstitutional  uneasily  last-ditch  Label  \n",
       "0                 0         0           0      1  \n",
       "1                 0         0           0      1  \n",
       "2                 0         0           0      1  \n",
       "3                 0         0           0      1  \n",
       "4                 0         0           0      1  \n",
       "\n",
       "[5 rows x 1901 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, row in df_test.iterrows():\n",
    "    featuresets.append((find_features(row[\"Review\"]), row[\"Label\"]))\n",
    "    \n",
    "df2 = pd.DataFrame.from_dict(featuresets)\n",
    "df2.head()\n",
    "\n",
    "df_test = pd.json_normalize(df[0])\n",
    "df_test = df_train.astype(int)\n",
    "df_test[\"Label\"] = df2[1]\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Train and Test DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"stanford_train2.csv\")\n",
    "df_train.to_csv(\"stanford_test2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
