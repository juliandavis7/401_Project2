{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import requests\n",
    "import os\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, lr = 0.001, n_iters = 1000):\n",
    "        self.lr = lr\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.random.uniform(-1, 1, n_features)\n",
    "        self.bias = np.random.uniform(-1, 1, 1)[0]\n",
    "        \n",
    "        #gradient descent\n",
    "        for i in range(self.n_iters):\n",
    "            lin_model = np.dot(X, self.weights) + self.bias\n",
    "            y_pred = self._sigmoid(lin_model)\n",
    "            \n",
    "            dw = (1 / n_samples) * np.dot(X.T, (y_pred - y))\n",
    "            db = (1 / n_samples) * np.sum(y_pred - y)\n",
    "            \n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "            \n",
    "        \n",
    "    def predict(self, X, threshold):\n",
    "        lin_model = np.dot(X, self.weights) + self.bias\n",
    "        y_pred = self._sigmoid(lin_model)\n",
    "        y_pred_cls = [1 if i > threshold else -1 for i in y_pred]\n",
    "        return pd.DataFrame({'Probability': y_pred, 'Class': y_pred_cls})\n",
    "    \n",
    "    #helper sigmoid function\n",
    "    def _sigmoid(self, linear):\n",
    "        return 1 / (1 + np.exp(-linear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_metrics(actual, pred):\n",
    "    actual = pd.Series(actual)\n",
    "    pred = pd.Series(pred)\n",
    "    \n",
    "    TP = ((actual == 1) & (pred == 1)).sum()\n",
    "    FP = ((actual != 1) & (pred == 1)).sum()\n",
    "    TN = ((actual != 1) & (pred != 1)).sum()\n",
    "    FN = ((actual == 1) & (pred != 1)).sum()\n",
    "    \n",
    "    accuracy = (actual == pred).mean()\n",
    "    precision = TP / (pred == 1).sum()\n",
    "    recall = TP / (actual == 1).sum()\n",
    "    f1 = (2 * precision * recall) / (precision + recall)   \n",
    "    \n",
    "    \n",
    "    print({\"accuracy\":accuracy,\"precision\":precision,\"recall\":recall, \"F1 Score\":f1})\n",
    "    confusion_mat = pd.DataFrame({'Actually Positive': [TP, FN], \n",
    "                                  'Actually Negative': [FP, TN]},\n",
    "                                index = ['Predicted Positive', 'Predicted Negative'])    \n",
    "    \n",
    "    return confusion_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Set 1 - Positive and Negative Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train1.csv')\n",
    "test_df = pd.read_csv('test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(['Unnamed: 0', 'Label'], axis = 1)\n",
    "X_test = test_df.drop(['Unnamed: 0', 'Label'], axis = 1)\n",
    "y_train = train_df.Label\n",
    "y_test = test_df.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (minutes) elapsed for this cell: 0.027248027916357387\n",
      "{'accuracy': 0.5912, 'precision': 0.9247391952309985, 'recall': 0.19856, 'F1 Score': 0.32692307692307687}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actually Positive</th>\n",
       "      <th>Actually Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted Positive</th>\n",
       "      <td>2482</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted Negative</th>\n",
       "      <td>10018</td>\n",
       "      <td>12298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Actually Positive  Actually Negative\n",
       "Predicted Positive               2482                202\n",
       "Predicted Negative              10018              12298"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "lr = LogisticRegression(lr = 0.001, n_iters = 1000)\n",
    "lr.fit(X_train, y_train)\n",
    "pred = lr.predict(X_test, threshold = 0.5)\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print(\"Time (minutes) elapsed for this cell:\", elapsed/60)\n",
    "\n",
    "test_metrics(y_test, pred['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = X_train.copy()\n",
    "X_test2 = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2[\"Interaction_posc_negc\"] = X_train2.Positive_counts*X_train2.Negative_counts\n",
    "X_test2[\"Interaction_posc_negc\"] = X_test2.Positive_counts*X_test2.Negative_counts\n",
    "X_train2 = X_train2[[\"Positive_counts\",\"Negative_counts\",\"Interaction_posc_negc\"]]\n",
    "X_test2 = X_test2[[\"Positive_counts\",\"Negative_counts\",\"Interaction_posc_negc\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (minutes) elapsed for this cell: 0.028207414533244445\n",
      "{'accuracy': 0.61684, 'precision': 0.8929244013989777, 'recall': 0.26552, 'F1 Score': 0.40932354936178084}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actually Positive</th>\n",
       "      <th>Actually Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted Positive</th>\n",
       "      <td>3319</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted Negative</th>\n",
       "      <td>9181</td>\n",
       "      <td>12102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Actually Positive  Actually Negative\n",
       "Predicted Positive               3319                398\n",
       "Predicted Negative               9181              12102"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "lr2 = LogisticRegression(lr = 0.001, n_iters = 1000)\n",
    "lr2.fit(X_train2, y_train)\n",
    "pred2 = lr2.predict(X_test2, threshold = 0.5)\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print(\"Time (minutes) elapsed for this cell:\", elapsed/60)\n",
    "\n",
    "test_metrics(y_test, pred2['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squared Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3 = X_train2.copy()\n",
    "X_test3 = X_test2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3[\"Positive_counts2\"] = X_train3.Positive_counts**2\n",
    "X_train3[\"Negative_counts2\"] = X_train3.Negative_counts**2\n",
    "X_test3[\"Positive_counts2\"] = X_test3.Positive_counts**2\n",
    "X_test3[\"Negative_counts2\"] = X_test3.Negative_counts**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:33: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (minutes) elapsed for this cell: 0.029927547866342743\n",
      "{'accuracy': 0.66136, 'precision': 0.870635795663359, 'recall': 0.37904, 'F1 Score': 0.5281462490246349}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actually Positive</th>\n",
       "      <th>Actually Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted Positive</th>\n",
       "      <td>4738</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted Negative</th>\n",
       "      <td>7762</td>\n",
       "      <td>11796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Actually Positive  Actually Negative\n",
       "Predicted Positive               4738                704\n",
       "Predicted Negative               7762              11796"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "lr3 = LogisticRegression(lr = 0.001, n_iters = 1000)\n",
    "lr3.fit(X_train3, y_train)\n",
    "pred3 = lr3.predict(X_test3, threshold = 0.5)\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print(\"Time (minutes) elapsed for this cell:\", elapsed/60)\n",
    "\n",
    "test_metrics(y_test, pred3['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cubed Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train4 = X_train3.copy()\n",
    "X_test4 = X_test3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train4[\"Positive_counts3\"] = X_train3.Positive_counts**3\n",
    "X_train4[\"Negative_counts3\"] = X_train3.Negative_counts**3\n",
    "X_test4[\"Positive_counts3\"] = X_test3.Positive_counts**3\n",
    "X_test4[\"Negative_counts3\"] = X_test3.Negative_counts**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:33: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (minutes) elapsed for this cell: 0.03181885458325269\n",
      "{'accuracy': 0.696, 'precision': 0.8333333333333334, 'recall': 0.49, 'F1 Score': 0.6171284634760705}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actually Positive</th>\n",
       "      <th>Actually Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted Positive</th>\n",
       "      <td>6125</td>\n",
       "      <td>1225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted Negative</th>\n",
       "      <td>6375</td>\n",
       "      <td>11275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Actually Positive  Actually Negative\n",
       "Predicted Positive               6125               1225\n",
       "Predicted Negative               6375              11275"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "lr4 = LogisticRegression(lr = 0.001, n_iters = 1000)\n",
    "lr4.fit(X_train4, y_train)\n",
    "pred4 = lr4.predict(X_test4, threshold = 0.5)\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print(\"Time (minutes) elapsed for this cell:\", elapsed/60)\n",
    "\n",
    "test_metrics(y_test, pred4['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Threshold Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:33: RuntimeWarning: overflow encountered in exp\n",
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:33: RuntimeWarning: overflow encountered in exp\n",
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:33: RuntimeWarning: overflow encountered in exp\n",
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:33: RuntimeWarning: overflow encountered in exp\n",
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:33: RuntimeWarning: overflow encountered in exp\n",
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:33: RuntimeWarning: overflow encountered in exp\n",
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:33: RuntimeWarning: overflow encountered in exp\n",
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:33: RuntimeWarning: overflow encountered in exp\n",
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:33: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Probability Threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Probability Threshold  Accuracy\n",
       "0                    0.1     0.696\n",
       "0                    0.2     0.696\n",
       "0                    0.3     0.696\n",
       "0                    0.4     0.696\n",
       "0                    0.5     0.696\n",
       "0                    0.6     0.696\n",
       "0                    0.7     0.696\n",
       "0                    0.8     0.696\n",
       "0                    0.9     0.696"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = [x * 0.1 for x in range(0, 10) if x != 0]\n",
    "probs_df = pd.DataFrame({'Probability Threshold': [], 'Accuracy': []})\n",
    "for i in range(len(probs)):\n",
    "    pred_prob = lr4.predict(X_test4, threshold = probs[i])\n",
    "    probs_df = pd.concat([probs_df,\n",
    "                         pd.DataFrame({'Probability Threshold': [probs[i]], 'Accuracy': [(pred_prob['Class'] == y_test_stan).mean()]})])\n",
    "    \n",
    "probs_df.reset_index(inplace = True)\n",
    "probs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.696, 'precision': 0.8328804347826086, 'recall': 0.4904, 'F1 Score': 0.6173212487411883}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.7/site-packages/ipykernel_launcher.py:33: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actually Positive</th>\n",
       "      <th>Actually Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted Positive</th>\n",
       "      <td>6130</td>\n",
       "      <td>1230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted Negative</th>\n",
       "      <td>6370</td>\n",
       "      <td>11270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Actually Positive  Actually Negative\n",
       "Predicted Positive               6130               1230\n",
       "Predicted Negative               6370              11270"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_acc_index = probs_df.idxmax(axis = 0)['Accuracy']\n",
    "highest_acc_thresh = list(probs_df['Probability Threshold'])[highest_acc_index]\n",
    "test_metrics(y_test, lr4.predict(X_test4, threshold = highest_acc_thresh)['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = pd.read_csv('train2.csv')\n",
    "test2 = pd.read_csv('test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train2.drop(\"Unnamed: 0\",axis=1)\n",
    "test2 = test2.drop(\"Unnamed: 0\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_adj = train2.drop('Label', axis = 1)\n",
    "X_test_adj = test2.drop('Label', axis = 1)\n",
    "y_train_adj = train2.Label\n",
    "y_test_adj = test2.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (minutes) elapsed for this cell: 10.78126423395006\n",
      "{'accuracy': 0.51004, 'precision': 0.5147076057658502, 'recall': 0.35136, 'F1 Score': 0.41762943945228925}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actually Positive</th>\n",
       "      <th>Actually Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted Positive</th>\n",
       "      <td>4392</td>\n",
       "      <td>4141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted Negative</th>\n",
       "      <td>8108</td>\n",
       "      <td>8359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Actually Positive  Actually Negative\n",
       "Predicted Positive               4392               4141\n",
       "Predicted Negative               8108               8359"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "lr_adj = LogisticRegression(lr = 0.001, n_iters = 1000)\n",
    "lr_adj.fit(X_train_adj, y_train_adj)\n",
    "pred_adj = lr_adj.predict(X_test_adj, threshold = 0.5)\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print(\"Time (minutes) elapsed for this cell:\", elapsed/60)\n",
    "\n",
    "test_metrics(y_test_adj, pred_adj['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Threshold Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Probability Threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.50876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.50896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.51072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.51120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.51004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.50844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.50600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.50620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.50548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Probability Threshold  Accuracy\n",
       "0                    0.1   0.50876\n",
       "0                    0.2   0.50896\n",
       "0                    0.3   0.51072\n",
       "0                    0.4   0.51120\n",
       "0                    0.5   0.51004\n",
       "0                    0.6   0.50844\n",
       "0                    0.7   0.50600\n",
       "0                    0.8   0.50620\n",
       "0                    0.9   0.50548"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = [x * 0.1 for x in range(0, 10) if x != 0]\n",
    "probs_df = pd.DataFrame({'Probability Threshold': [], 'Accuracy': []})\n",
    "for i in range(len(probs)):\n",
    "    pred_prob = lr_adj.predict(X_test_adj, threshold = probs[i])\n",
    "    probs_df = pd.concat([probs_df,\n",
    "                         pd.DataFrame({'Probability Threshold': [probs[i]], 'Accuracy': [(pred_prob['Class'] == y_test_stan).mean()]})])\n",
    "    \n",
    "probs_df.reset_index(inplace = True)\n",
    "probs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.5112, 'precision': 0.514297385620915, 'recall': 0.40288, 'F1 Score': 0.4518212811771039}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actually Positive</th>\n",
       "      <th>Actually Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted Positive</th>\n",
       "      <td>5036</td>\n",
       "      <td>4756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted Negative</th>\n",
       "      <td>7464</td>\n",
       "      <td>7744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Actually Positive  Actually Negative\n",
       "Predicted Positive               5036               4756\n",
       "Predicted Negative               7464               7744"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_acc_index = probs_df.idxmax(axis = 0)['Accuracy']\n",
    "highest_acc_thresh = list(probs_df['Probability Threshold'])[highest_acc_index]\n",
    "test_metrics(y_test, lr_adj.predict(X_test_adj, threshold = highest_acc_thresh)['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stanford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "stanford_train = pd.read_csv('standford_train.csv')\n",
    "stanford_test = pd.read_csv('stanford_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "stanford_train = stanford_train.drop(\"Unnamed: 0\",axis=1)\n",
    "stanford_test = stanford_test.drop(\"Unnamed: 0\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stan = stanford_train.drop('Label', axis = 1)\n",
    "X_test_stan = stanford_test.drop('Label', axis = 1)\n",
    "y_train_stan = stanford_train.Label\n",
    "y_test_stan = stanford_test.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (minutes) elapsed for this cell: 0.8860726735331507\n",
      "{'accuracy': 0.48968, 'precision': 0.48788277287244036, 'recall': 0.41552, 'F1 Score': 0.4488032489415018}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actually Positive</th>\n",
       "      <th>Actually Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted Positive</th>\n",
       "      <td>5194</td>\n",
       "      <td>5452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted Negative</th>\n",
       "      <td>7306</td>\n",
       "      <td>7048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Actually Positive  Actually Negative\n",
       "Predicted Positive               5194               5452\n",
       "Predicted Negative               7306               7048"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "lr_stan = LogisticRegression(lr = 0.001, n_iters = 1000)\n",
    "lr_stan.fit(X_train_stan, y_train_stan)\n",
    "pred_stan = lr_stan.predict(X_test_stan, threshold = 0.5)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print(\"Time (minutes) elapsed for this cell:\", elapsed/60)\n",
    "\n",
    "test_metrics(y_test_stan, pred_stan['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Threshold Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Probability Threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.49228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.48980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.48936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.48912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.48968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.49196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.49168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.49324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.49640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Probability Threshold  Accuracy\n",
       "0      0                    0.1   0.49228\n",
       "1      0                    0.2   0.48980\n",
       "2      0                    0.3   0.48936\n",
       "3      0                    0.4   0.48912\n",
       "4      0                    0.5   0.48968\n",
       "5      0                    0.6   0.49196\n",
       "6      0                    0.7   0.49168\n",
       "7      0                    0.8   0.49324\n",
       "8      0                    0.9   0.49640"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_df = pd.DataFrame({'Probability Threshold': [], 'Accuracy': []})\n",
    "for i in range(len(probs)):\n",
    "    pred_prob = lr_stan.predict(X_test_stan, threshold = probs[i])\n",
    "    probs_df = pd.concat([probs_df,\n",
    "                         pd.DataFrame({'Probability Threshold': [probs[i]], 'Accuracy': [(pred_prob['Class'] == y_test_stan).mean()]})])\n",
    "    \n",
    "probs_df.reset_index(inplace = True)\n",
    "probs_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.4964, 'precision': 0.4941588785046729, 'recall': 0.30456, 'F1 Score': 0.3768560681053257}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actually Positive</th>\n",
       "      <th>Actually Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted Positive</th>\n",
       "      <td>3807</td>\n",
       "      <td>3897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted Negative</th>\n",
       "      <td>8693</td>\n",
       "      <td>8603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Actually Positive  Actually Negative\n",
       "Predicted Positive               3807               3897\n",
       "Predicted Negative               8693               8603"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_acc_index = probs_df.idxmax(axis = 0)['Accuracy']\n",
    "highest_acc_thresh = list(probs_df['Probability Threshold'])[highest_acc_index]\n",
    "test_metrics(y_test, lr_stan.predict(X_test_stan, threshold = highest_acc_thresh)['Class'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
