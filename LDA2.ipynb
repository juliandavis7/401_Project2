{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from collections import Counter\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import pickle\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a dictionary of priors (one key, value pair for each category)\n",
    "def compute_priors(df, response):\n",
    "    y = df[response]\n",
    "    priors_dict = {}\n",
    "    priors = dict(y.value_counts(normalize=True))\n",
    "    return priors\n",
    "\n",
    "# returns a dictionary of mu vectors (one key, value pair for each category)\n",
    "def compute_mu_vectors(df, response):\n",
    "    y = df[response]\n",
    "    mu_vectors = {}\n",
    "    for category_k in y.unique():\n",
    "        df_k = df[y == category_k] # df with y = category_k\n",
    "        X_k = df_k.drop(response, axis=1)\n",
    "        mu_vectors[category_k] = dict(X_k.mean())\n",
    "    return mu_vectors\n",
    "\n",
    "# returns the inverse of the covariance matrix\n",
    "def compute_inv_sigma(df, response):\n",
    "    X = df.drop(response, axis=1)\n",
    "    return inv(X.cov())\n",
    "\n",
    "# returns the classification of a single obs\n",
    "def classify_obs(x_i, y, mu_vectors, priors, inv_sigma):\n",
    "        prob_dict = {}\n",
    "        for category_k in y.unique():\n",
    "            mu_k = pd.Series(mu_vectors[category_k]).to_numpy()\n",
    "            first_term = x_i.transpose().dot(inv_sigma).dot(mu_k)\n",
    "            second_term = .5 * mu_k.transpose().dot(inv_sigma).dot(mu_k)\n",
    "            third_term = np.log(priors[category_k])\n",
    "            prob_k = first_term - second_term + third_term\n",
    "            prob_dict[category_k] = prob_k\n",
    "\n",
    "        best_class, max_prob = next(iter(prob_dict.items()))\n",
    "        for class_k, prob_k in prob_dict.items():\n",
    "            if max_prob < prob_k:\n",
    "                max_prob = prob_k\n",
    "                best_class = class_k\n",
    "        return best_class\n",
    "\n",
    "class LDA:\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        df_train = X_train.copy()\n",
    "        response = y_train.name\n",
    "        df_train[response] = y_train\n",
    "        self.y = df_train[response]\n",
    "        self.priors = compute_priors(df_train, response)\n",
    "        self.mu_vectors = compute_mu_vectors(df_train, response)\n",
    "        self.inv_sigma = compute_inv_sigma(df_train, response)\n",
    "        \n",
    "    def predict(self, df_test):\n",
    "        y_pred = {}\n",
    "        for i in range(len(df_test)):\n",
    "            x_i = df_test.loc[i, :].to_numpy()\n",
    "            y_pred[i] = classify_obs(x_i, self.y, self.mu_vectors, self.priors, self.inv_sigma)\n",
    "        return pd.Series(y_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Compute Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_confusion_matrix(y_pred, y_test):\n",
    "    res = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test})\n",
    "\n",
    "    res_positives = res[res[\"Actual\"] == 1]\n",
    "    res_negatives = res[res[\"Actual\"] == -1]\n",
    "\n",
    "    positives_dict = dict(res_positives[\"Prediction\"].value_counts(normalize=True))\n",
    "    TPs = positives_dict[1]\n",
    "    FNs = positives_dict[-1]\n",
    "\n",
    "    negatives_dict = dict(res_negatives[\"Prediction\"].value_counts(normalize=True))\n",
    "    TNs = negatives_dict[-1]\n",
    "    FPs = negatives_dict[1]\n",
    "\n",
    "    positives = pd.Series([TPs, FNs])\n",
    "    negatives = pd.Series([FPs, TNs])\n",
    "\n",
    "    confusion_matrix = pd.DataFrame({\"Actually Positive\": positives, \"Actually Negative\": negatives})\n",
    "    confusion_matrix.rename({0: \"Prediced Positive\", 1: \"Predicted Negative\"}, inplace=True)\n",
    "    return confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"tf_idf_train2.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "df_test = pd.read_csv(\"tf_idf_test2.csv\").drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>life</th>\n",
       "      <th>comedy</th>\n",
       "      <th>whole</th>\n",
       "      <th>reality</th>\n",
       "      <th>cartoon</th>\n",
       "      <th>good</th>\n",
       "      <th>also</th>\n",
       "      <th>stories</th>\n",
       "      <th>behaved</th>\n",
       "      <th>cross</th>\n",
       "      <th>...</th>\n",
       "      <th>amazons-dr</th>\n",
       "      <th>now-over</th>\n",
       "      <th>creature-basically</th>\n",
       "      <th>mud-wrestling</th>\n",
       "      <th>multi-sexual</th>\n",
       "      <th>barabarian</th>\n",
       "      <th>gamorrean</th>\n",
       "      <th>d-grade</th>\n",
       "      <th>highly-entertaining</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.734095</td>\n",
       "      <td>2.38033</td>\n",
       "      <td>2.250752</td>\n",
       "      <td>3.455865</td>\n",
       "      <td>4.257334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.38033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.900542</td>\n",
       "      <td>2.707422</td>\n",
       "      <td>3.329807</td>\n",
       "      <td>7.082109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.675593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.353711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8350 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       life   comedy     whole   reality   cartoon      good      also  \\\n",
       "0  1.734095  2.38033  2.250752  3.455865  4.257334  0.000000  0.000000   \n",
       "1  0.000000  2.38033  0.000000  0.000000  0.000000  2.900542  2.707422   \n",
       "2  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  1.353711   \n",
       "\n",
       "    stories   behaved     cross  ...  amazons-dr  now-over  \\\n",
       "0  0.000000  0.000000  0.000000  ...         0.0       0.0   \n",
       "1  3.329807  7.082109  0.000000  ...         0.0       0.0   \n",
       "2  0.000000  0.000000  4.675593  ...         0.0       0.0   \n",
       "3  0.000000  0.000000  0.000000  ...         0.0       0.0   \n",
       "4  0.000000  0.000000  0.000000  ...         0.0       0.0   \n",
       "\n",
       "   creature-basically  mud-wrestling  multi-sexual  barabarian  gamorrean  \\\n",
       "0                 0.0            0.0           0.0         0.0        0.0   \n",
       "1                 0.0            0.0           0.0         0.0        0.0   \n",
       "2                 0.0            0.0           0.0         0.0        0.0   \n",
       "3                 0.0            0.0           0.0         0.0        0.0   \n",
       "4                 0.0            0.0           0.0         0.0        0.0   \n",
       "\n",
       "   d-grade  highly-entertaining  Label  \n",
       "0      0.0                  0.0      1  \n",
       "1      0.0                  0.0      1  \n",
       "2      0.0                  0.0      1  \n",
       "3      0.0                  0.0      1  \n",
       "4      0.0                  0.0      1  \n",
       "\n",
       "[5 rows x 8350 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>good</th>\n",
       "      <th>well</th>\n",
       "      <th>comedy</th>\n",
       "      <th>overcome</th>\n",
       "      <th>coaxed</th>\n",
       "      <th>also</th>\n",
       "      <th>love</th>\n",
       "      <th>something</th>\n",
       "      <th>must</th>\n",
       "      <th>tv</th>\n",
       "      <th>...</th>\n",
       "      <th>aggrandizement</th>\n",
       "      <th>uneventfully</th>\n",
       "      <th>feng</th>\n",
       "      <th>satans</th>\n",
       "      <th>day-for-night</th>\n",
       "      <th>preppie</th>\n",
       "      <th>dines</th>\n",
       "      <th>bleibtreu</th>\n",
       "      <th>terminating</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.997067</td>\n",
       "      <td>2.532548</td>\n",
       "      <td>2.375586</td>\n",
       "      <td>5.330841</td>\n",
       "      <td>8.740337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.997067</td>\n",
       "      <td>1.266274</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.798821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.379756</td>\n",
       "      <td>1.735455</td>\n",
       "      <td>1.821889</td>\n",
       "      <td>2.212013</td>\n",
       "      <td>2.49423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.997067</td>\n",
       "      <td>3.798821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4726 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       good      well    comedy  overcome    coaxed      also      love  \\\n",
       "0  0.997067  2.532548  2.375586  5.330841  8.740337  0.000000  0.000000   \n",
       "1  0.997067  1.266274  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000  3.798821  0.000000  0.000000  0.000000  1.379756  1.735455   \n",
       "3  0.997067  3.798821  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "   something      must       tv  ...  aggrandizement  uneventfully  feng  \\\n",
       "0   0.000000  0.000000  0.00000  ...             0.0           0.0   0.0   \n",
       "1   0.000000  0.000000  0.00000  ...             0.0           0.0   0.0   \n",
       "2   1.821889  2.212013  2.49423  ...             0.0           0.0   0.0   \n",
       "3   0.000000  0.000000  0.00000  ...             0.0           0.0   0.0   \n",
       "4   0.000000  0.000000  0.00000  ...             0.0           0.0   0.0   \n",
       "\n",
       "   satans  day-for-night  preppie  dines  bleibtreu  terminating  Label  \n",
       "0     0.0            0.0      0.0    0.0        0.0          0.0      1  \n",
       "1     0.0            0.0      0.0    0.0        0.0          0.0      1  \n",
       "2     0.0            0.0      0.0    0.0        0.0          0.0      1  \n",
       "3     0.0            0.0      0.0    0.0        0.0          0.0      1  \n",
       "4     0.0            0.0      0.0    0.0        0.0          0.0      1  \n",
       "\n",
       "[5 rows x 4726 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(\"Label\", axis=1)\n",
    "y_train = df_train[\"Label\"]\n",
    "X_test = df_test.drop(\"Label\", axis=1)\n",
    "y_test = df_test[\"Label\"]\n",
    "\n",
    "model = LDA()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "(y_pred == y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = produce_confusion_matrix(y_pred, y_test)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2893_10.txt</td>\n",
       "      <td>Walt Disney's CINDERELLA takes a story everybo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7944_9.txt</td>\n",
       "      <td>Have you ever, or do you have, a pet who's bee...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11725_10.txt</td>\n",
       "      <td>I suck at gratuitous Boob references, so i'm j...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1587_10.txt</td>\n",
       "      <td>Does anyone know, where I can see or download ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10297_8.txt</td>\n",
       "      <td>Well not actually. This movie is very entertai...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           File                                             Review  Label\n",
       "0   2893_10.txt  Walt Disney's CINDERELLA takes a story everybo...      1\n",
       "1    7944_9.txt  Have you ever, or do you have, a pet who's bee...      1\n",
       "2  11725_10.txt  I suck at gratuitous Boob references, so i'm j...      1\n",
       "3   1587_10.txt  Does anyone know, where I can see or download ...      1\n",
       "4   10297_8.txt  Well not actually. This movie is very entertai...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df = pd.read_csv(\"Training_data.csv\").drop(\"Unnamed: 0\",axis=1)\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2893_10.txt</td>\n",
       "      <td>\"Rush in Rio\" is, no doubt, one of the most ex...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8705_10.txt</td>\n",
       "      <td>I have seen a number of horror movies to know ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11725_10.txt</td>\n",
       "      <td>I'm a fan of B grade 80s films in which the he...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9859_8.txt</td>\n",
       "      <td>I think that Pierre Léaud, or his character, t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12409_10.txt</td>\n",
       "      <td>This picture doesn't have any big explosions o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           File                                             Review  Label\n",
       "0   2893_10.txt  \"Rush in Rio\" is, no doubt, one of the most ex...      1\n",
       "1   8705_10.txt  I have seen a number of horror movies to know ...      1\n",
       "2  11725_10.txt  I'm a fan of B grade 80s films in which the he...      1\n",
       "3    9859_8.txt  I think that Pierre Léaud, or his character, t...      1\n",
       "4  12409_10.txt  This picture doesn't have any big explosions o...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_df = pd.read_csv(\"Test_data.csv\").drop(\"Unnamed: 0\",axis=1)\n",
    "testing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop words\n",
    "from nltk.corpus import stopwords\n",
    "en_stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive semantic words\n",
    "url = \"https://raw.githubusercontent.com/jeffreybreen/twitter-sentiment-analysis-tutorial-201107/master/data/opinion-lexicon-English/positive-words.txt\"\n",
    "r = requests.get(url)\n",
    "s=';;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\\n; \\n; Opinion Lexicon: Positive\\n;\\n; This file contains a list of POSITIVE opinion words (or sentiment words).\\n;\\n; This file and the papers can all be downloaded from \\n;    http://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html\\n;\\n; If you use this list, please cite one of the following two papers:\\n;\\n;   Minqing Hu and Bing Liu. \"Mining and Summarizing Customer Reviews.\" \\n;       Proceedings of the ACM SIGKDD International Conference on Knowledge \\n;       Discovery and Data Mining (KDD-2004), Aug 22-25, 2004, Seattle, \\n;       Washington, USA, \\n;   Bing Liu, Minqing Hu and Junsheng Cheng. \"Opinion Observer: Analyzing \\n;       and Comparing Opinions on the Web.\" Proceedings of the 14th \\n;       International World Wide Web conference (WWW-2005), May 10-14, \\n;       2005, Chiba, Japan.\\n;\\n; Notes: \\n;    1. The appearance of an opinion word in a sentence does not necessarily  \\n;       mean that the sentence expresses a positive or negative opinion. \\n;       See the paper below:\\n;\\n;       Bing Liu. \"Sentiment Analysis and Subjectivity.\" An chapter in \\n;          Handbook of Natural Language Processing, Second Edition, \\n;          (editors: N. Indurkhya and F. J. Damerau), 2010.\\n;\\n;    2. You will notice many misspelled words in the list. They are not \\n;       mistakes. They are included as these misspelled words appear \\n;       frequently in social media content. \\n;\\n;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;'\n",
    "pos_words = r.text[len(s)+2:]\n",
    "pos_words = pos_words.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative semantic words\n",
    "url = \"https://raw.githubusercontent.com/jeffreybreen/twitter-sentiment-analysis-tutorial-201107/master/data/opinion-lexicon-English/negative-words.txt\"\n",
    "r = requests.get(url)\n",
    "s=';;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\\n; \\n; Opinion Lexicon: Negative\\n;\\n; This file contains a list of NEGATIVE opinion words (or sentiment words).\\n;\\n; This file and the papers can all be downloaded from \\n;    http://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html\\n;\\n; If you use this list, please cite one of the following two papers:\\n;\\n;   Minqing Hu and Bing Liu. \"Mining and Summarizing Customer Reviews.\" \\n;       Proceedings of the ACM SIGKDD International Conference on Knowledge \\n;       Discovery and Data Mining (KDD-2004), Aug 22-25, 2004, Seattle, \\n;       Washington, USA, \\n;   Bing Liu, Minqing Hu and Junsheng Cheng. \"Opinion Observer: Analyzing \\n;       and Comparing Opinions on the Web.\" Proceedings of the 14th \\n;       International World Wide Web conference (WWW-2005), May 10-14, \\n;       2005, Chiba, Japan.\\n;\\n; Notes: \\n;    1. The appearance of an opinion word in a sentence does not necessarily  \\n;       mean that the sentence expresses a positive or negative opinion. \\n;       See the paper below:\\n;\\n;       Bing Liu. \"Sentiment Analysis and Subjectivity.\" An chapter in \\n;          Handbook of Natural Language Processing, Second Edition, \\n;          (editors: N. Indurkhya and F. J. Damerau), 2010.\\n;\\n;    2. You will notice many misspelled words in the list. They are not \\n;       mistakes. They are included as these misspelled words appear \\n;       frequently in social media content. \\n;\\n;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\\n\\n'\n",
    "neg_words = r.text[len(s):]\n",
    "neg_words = neg_words.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engineering the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing reviews in training set\n",
    "words_train = (\n",
    "    training_df.Review.\n",
    "    str.lower().\n",
    "    str.replace(\"[^\\w\\s]\",\"\").\n",
    "    str.split()\n",
    ")\n",
    "bag_of_words_train = words_train.apply(Counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing reviews in test set\n",
    "words_test = (\n",
    "    testing_df.Review.\n",
    "    str.lower().\n",
    "    str.replace(\"[^\\w\\s]\",\"\").\n",
    "    str.split()\n",
    ")\n",
    "bag_of_words_test = words_test.apply(Counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stop words in training\n",
    "reviews_train = []\n",
    "for r in words_train:\n",
    "    good = []\n",
    "    for w in r:\n",
    "        if w not in en_stops:\n",
    "            good.append(w)\n",
    "    reviews_train.append(good)\n",
    "reviews_train = pd.Series(reviews_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stop words in test\n",
    "reviews_test = []\n",
    "for r in words_test:\n",
    "    good = []\n",
    "    for w in r:\n",
    "        if w not in en_stops:\n",
    "            good.append(w)\n",
    "    reviews_test.append(good)\n",
    "reviews_test = pd.Series(reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting positive and negative words in training set\n",
    "pos_set = set(pos_words)\n",
    "neg_set = set(neg_words)\n",
    "posc_train = []\n",
    "negc_train = []\n",
    "for r in reviews_train:\n",
    "    count_pos = len(pos_set.intersection(set(r)))\n",
    "    count_neg = len(neg_set.intersection(set(r)))\n",
    "    posc_train.append(count_pos)\n",
    "    negc_train.append(count_neg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting positive and negative words in test set\n",
    "pos_set = set(pos_words)\n",
    "neg_set = set(neg_words)\n",
    "posc_test = []\n",
    "negc_test = []\n",
    "for r in reviews_test:\n",
    "    count_pos = len(pos_set.intersection(set(r)))\n",
    "    count_neg = len(neg_set.intersection(set(r)))\n",
    "    posc_test.append(count_pos)\n",
    "    negc_test.append(count_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = training_df.Label\n",
    "X_train = pd.DataFrame({\"Positive_counts\":posc_train, \"Negative_counts\":negc_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = testing_df.Label\n",
    "X_test = pd.DataFrame({\"Positive_counts\":posc_test, \"Negative_counts\":negc_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA classifier results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73068"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LDA()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "(y_pred == y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actually Positive</th>\n",
       "      <th>Actually Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Prediced Positive</th>\n",
       "      <td>0.7208</td>\n",
       "      <td>0.25944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted Negative</th>\n",
       "      <td>0.2792</td>\n",
       "      <td>0.74056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Actually Positive  Actually Negative\n",
       "Prediced Positive              0.7208            0.25944\n",
       "Predicted Negative             0.2792            0.74056"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = produce_confusion_matrix(y_pred, y_test)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = X_train.copy()\n",
    "X_test2 = X_test.copy()\n",
    "y_train2 = y_train.copy()\n",
    "y_test2 = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2[\"Interaction_posc_negc\"] = X_train2.Positive_counts*X_train2.Negative_counts\n",
    "X_test2[\"Interaction_posc_negc\"] = X_test2.Positive_counts*X_test2.Negative_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73484"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = LDA()\n",
    "model2.fit(X_train2, y_train2)\n",
    "y_pred2 = model2.predict(X_test2)\n",
    "(y_pred2 == y_test2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Squaring Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3 = X_train2.copy()\n",
    "X_test3 = X_test2.copy()\n",
    "y_train3 = y_train2.copy()\n",
    "y_test3 = y_test2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3[\"Positive_counts2\"] = X_train3.Positive_counts**2\n",
    "X_train3[\"Negative_counts2\"] = X_train3.Negative_counts**2\n",
    "X_test3[\"Positive_counts2\"] = X_test3.Positive_counts**2\n",
    "X_test3[\"Negative_counts2\"] = X_test3.Negative_counts**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73428"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = LDA()\n",
    "model3.fit(X_train3, y_train3)\n",
    "y_pred3 = model3.predict(X_test3)\n",
    "(y_pred3 == y_test3).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cubing Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train4 = X_train3.copy()\n",
    "X_test4 = X_test3.copy()\n",
    "y_train4 = y_train3.copy()\n",
    "y_test4 = y_test3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train4[\"Positive_counts3\"] = X_train4.Positive_counts**3\n",
    "X_train4[\"Negative_counts3\"] = X_train4.Negative_counts**3\n",
    "X_test4[\"Positive_counts3\"] = X_test4.Positive_counts**3\n",
    "X_test4[\"Negative_counts3\"] = X_test4.Negative_counts**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73424"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = LDA()\n",
    "model4.fit(X_train4, y_train4)\n",
    "y_pred4 = model4.predict(X_test4)\n",
    "(y_pred4 == y_test4).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
